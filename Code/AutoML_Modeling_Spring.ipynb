{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5220a5bc",
   "metadata": {},
   "source": [
    "# AutoML을 활용한 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57047f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "# imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# model learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervised.automl import AutoML\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# 평가 지표\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 모델 저장\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6ce808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/spring_impute.csv')\n",
    "test = pd.read_csv('../data/spring_test_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b2a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train & valid data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    data[data.columns.difference(['ts', 'stn', 'year'])],\n",
    "    data['ts'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e54b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl modeling\n",
    "automl = AutoML(mode=\"Compete\",\n",
    "                algorithms=[\"Baseline\",\n",
    "                            \"CatBoost\",\n",
    "                            \"Xgboost\",\n",
    "                            \"Random Forest\",\n",
    "                            \"Extra Trees\",\n",
    "                            \"LightGBM\",\n",
    "                            \"Neural Network\",\n",
    "                            \"CatBoost\"],\n",
    "                ml_task = \"regression\",\n",
    "                eval_metric = \"mae\",\n",
    "                random_state = 42\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bc085",
   "metadata": {},
   "source": [
    "- `Explain` : To to be used when the user wants to explain and understand the data.\n",
    "                    - Uses 75%/25% train/test split.\n",
    "                    - Uses the following models: `Baseline`, `Linear`, `Decision Tree`, `Random Forest`, `XGBoost`, `Neural Network`, and `Ensemble`.\n",
    "                    - Has full explanations in reports: learning curves, importance plots, and SHAP plots.\n",
    "                    \n",
    "- `Perform` : To be used when the user wants to train a model that will be used in real-life use cases.\n",
    "                    - Uses 5-fold CV (Cross-Validation).\n",
    "                    - Uses the following models: `Linear`, `Random Forest`, `LightGBM`, `XGBoost`, `CatBoost`, `Neural Network`, and `Ensemble`.\n",
    "                    - Has learning curves and importance plots in reports.\n",
    "\n",
    "- `Compete` : To be used for machine learning competitions (maximum performance).\n",
    "                    - Uses 80/20 train/test split, or 5-fold CV, or 10-fold CV (Cross-Validation) - it depends on `total_time_limit`. If not set directly, AutoML will select validation automatically.\n",
    "                    - Uses the following models: `Decision Tree`, `Random Forest`, `Extra Trees`, `LightGBM`,  `XGBoost`, `CatBoost`, `Neural Network`,\n",
    "                        `Nearest Neighbors`, `Ensemble`, and `Stacking`.\n",
    "                    - It has only learning curves in the reports.\n",
    "\n",
    "- `Optuna` : To be used for creating highly-tuned machine learning models.\n",
    "                    - Uses 10-fold CV (Cross-Validation).\n",
    "                    - It tunes with Optuna the following algorithms: `Random Forest`, `Extra Trees`, `LightGBM`, `XGBoost`, `CatBoost`, `Neural Network`.\n",
    "                    - It applies `Ensemble` and `Stacking` for trained models.\n",
    "                    - It has only learning curves in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd1df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_20\n",
      "The task is regression with evaluation metric mae\n",
      "AutoML will use algorithms: ['Baseline', 'CatBoost', 'Xgboost', 'Random Forest', 'Extra Trees', 'LightGBM', 'Neural Network', 'CatBoost']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree mae 2.416005 trained in 0.58 seconds\n",
      "Adjust validation. Remove: 1_DecisionTree\n",
      "Validation strategy: 10-fold CV Shuffle\n",
      "* Step simple_algorithms will try to check up to 1 model\n",
      "1_Baseline mae 7.313985 trained in 2.33 seconds\n",
      "* Step default_algorithms will try to check up to 6 models\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7988\\395110505.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit automl mljar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\supervised\\automl.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, cv)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mAutoML\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mReturns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\supervised\\base_automl.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, cv)\u001b[0m\n\u001b[0;32m   1093\u001b[0m                             )\n\u001b[0;32m   1094\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1095\u001b[1;33m                             \u001b[0mtrained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1096\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"status\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"trained\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrained\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"skipped\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"final_loss\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_final_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\supervised\\base_automl.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;34mf\"Train model #{len(self._models)+1} / Model name: {params['name']}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         )\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_subpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# keep info about the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\supervised\\model_framework.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, results_path, model_subpath)\u001b[0m\n\u001b[0;32m    239\u001b[0m                         \u001b[0msample_weight_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         \u001b[0mlog_to_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_time_for_learner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m                     )\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\supervised\\algorithms\\lightgbm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, X_validation, y_validation, sample_weight_validation, log_to_file, max_time)\u001b[0m\n\u001b[0;32m    244\u001b[0m                 callbacks = [\n\u001b[0;32m    245\u001b[0m                     \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mesr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m                 ]\n\u001b[0;32m    248\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\please\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3021\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3023\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   3024\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit automl mljar\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "automl_pred = automl.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE값 구하기\n",
    "mean_absolute_error(y_valid, automl_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset의 예측값 구하기\n",
    "pred_test = automl.predict(test[test.columns.difference(['stn'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 가져오기\n",
    "test_result = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 넣기\n",
    "test_result['pred_ts'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write.csv\n",
    "test_result.to_csv('../data/spring_test_result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model_name = '002_plan'\n",
    "with open(model_name+'_spring_automl.pickle','wb') as fw:\n",
    "    pickle.dump(automl, fw)\n",
    "\n",
    "# 모델 불러오기\n",
    "# with open('model_210519.pickle', 'rb') as f: \n",
    "#     model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "please",
   "language": "python",
   "name": "please"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
