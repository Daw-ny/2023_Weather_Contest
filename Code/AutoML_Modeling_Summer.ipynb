{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae497ed4",
   "metadata": {},
   "source": [
    "# AutoML을 활용한 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aada3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "# imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# model learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervised.automl import AutoML\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# 평가 지표\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 모델 저장\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da841624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/summer_impute.csv')\n",
    "test = pd.read_csv('../data/summer_test_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c27c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train & valid data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    data[data.columns.difference(['ts', 'stn'])],\n",
    "    data['ts'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c959d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl modeling\n",
    "automl = AutoML(mode=\"Compete\",\n",
    "                algorithms=[\"Baseline\",\n",
    "                            \"CatBoost\",\n",
    "                            \"Xgboost\",\n",
    "                            \"Random Forest\",\n",
    "                            \"Extra Trees\",\n",
    "                            \"LightGBM\",\n",
    "                            \"Neural Network\",\n",
    "                            \"CatBoost\"],\n",
    "                ml_task = \"regression\",\n",
    "                eval_metric = \"mae\",\n",
    "                random_state = 42\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf3297",
   "metadata": {},
   "source": [
    "- `Explain` : To to be used when the user wants to explain and understand the data.\n",
    "                    - Uses 75%/25% train/test split.\n",
    "                    - Uses the following models: `Baseline`, `Linear`, `Decision Tree`, `Random Forest`, `XGBoost`, `Neural Network`, and `Ensemble`.\n",
    "                    - Has full explanations in reports: learning curves, importance plots, and SHAP plots.\n",
    "                    \n",
    "- `Perform` : To be used when the user wants to train a model that will be used in real-life use cases.\n",
    "                    - Uses 5-fold CV (Cross-Validation).\n",
    "                    - Uses the following models: `Linear`, `Random Forest`, `LightGBM`, `XGBoost`, `CatBoost`, `Neural Network`, and `Ensemble`.\n",
    "                    - Has learning curves and importance plots in reports.\n",
    "\n",
    "- `Compete` : To be used for machine learning competitions (maximum performance).\n",
    "                    - Uses 80/20 train/test split, or 5-fold CV, or 10-fold CV (Cross-Validation) - it depends on `total_time_limit`. If not set directly, AutoML will select validation automatically.\n",
    "                    - Uses the following models: `Decision Tree`, `Random Forest`, `Extra Trees`, `LightGBM`,  `XGBoost`, `CatBoost`, `Neural Network`,\n",
    "                        `Nearest Neighbors`, `Ensemble`, and `Stacking`.\n",
    "                    - It has only learning curves in the reports.\n",
    "\n",
    "- `Optuna` : To be used for creating highly-tuned machine learning models.\n",
    "                    - Uses 10-fold CV (Cross-Validation).\n",
    "                    - It tunes with Optuna the following algorithms: `Random Forest`, `Extra Trees`, `LightGBM`, `XGBoost`, `CatBoost`, `Neural Network`.\n",
    "                    - It applies `Ensemble` and `Stacking` for trained models.\n",
    "                    - It has only learning curves in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da19f2a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_3\n",
      "The task is regression with evaluation metric mae\n",
      "AutoML will use algorithms: ['Baseline', 'CatBoost', 'Xgboost', 'Random Forest', 'Extra Trees', 'LightGBM', 'Neural Network', 'CatBoost']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'mix_encoding', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree mae 2.136494 trained in 0.56 seconds\n",
      "Adjust validation. Remove: 1_DecisionTree\n",
      "Validation strategy: 10-fold CV Shuffle\n",
      "* Step simple_algorithms will try to check up to 1 model\n",
      "1_Baseline mae 6.235491 trained in 2.16 seconds\n",
      "* Step default_algorithms will try to check up to 6 models\n",
      "2_Default_LightGBM mae 1.065677 trained in 287.38 seconds\n",
      "3_Default_Xgboost mae 1.123889 trained in 126.57 seconds\n",
      "4_Default_CatBoost mae 1.152495 trained in 689.97 seconds\n",
      "* Step not_so_random will try to check up to 54 models\n",
      "14_LightGBM mae 1.110451 trained in 100.84 seconds\n",
      "5_Xgboost mae 1.136206 trained in 77.89 seconds\n",
      "23_CatBoost mae 1.134774 trained in 704.85 seconds\n",
      "Skip mix_encoding because of the time limit.\n",
      "Skip golden_features because of the time limit.\n",
      "* Step kmeans_features will try to check up to 3 models\n",
      "2_Default_LightGBM_KMeansFeatures mae 1.102548 trained in 283.0 seconds\n",
      "Not enough time to perform features selection. Skip\n",
      "Time needed for features selection ~ 707.0 seconds\n",
      "Please increase total_time_limit to at least (7126 seconds) to have features selection\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 11 models\n",
      "24_LightGBM mae 1.065677 trained in 283.98 seconds\n",
      "25_LightGBM mae 1.065677 trained in 277.65 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "26_LightGBM mae 1.074482 trained in 143.6 seconds\n",
      "* Step boost_on_errors will try to check up to 1 model\n",
      "2_Default_LightGBM_BoostOnErrors mae 1.074074 trained in 242.88 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble mae 1.05741 trained in 1.17 seconds\n",
      "* Step stack will try to check up to 10 models\n",
      "2_Default_LightGBM_Stacked mae 1.062677 trained in 34.37 seconds\n",
      "3_Default_Xgboost_Stacked mae 1.063217 trained in 37.71 seconds\n",
      "23_CatBoost_Stacked mae 1.067195 trained in 260.38 seconds\n",
      "24_LightGBM_Stacked not trained. Stop training after the first fold. Time needed to train on the first fold 2.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "5_Xgboost_Stacked not trained. Stop training after the first fold. Time needed to train on the first fold 2.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "4_Default_CatBoost_Stacked not trained. Stop training after the first fold. Time needed to train on the first fold 92.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "* Step ensemble_stacked will try to check up to 1 model\n",
      "Ensemble_Stacked mae 1.056589 trained in 2.98 seconds\n",
      "AutoML fit time: 3701.16 seconds\n",
      "AutoML best model: Ensemble_Stacked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML(algorithms=['Baseline', 'CatBoost', 'Xgboost', 'Random Forest',\n",
       "                   'Extra Trees', 'LightGBM', 'Neural Network', 'CatBoost'],\n",
       "       eval_metric='mae', ml_task='regression', mode='Compete',\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit automl mljar\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee02b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "automl_pred = automl.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43be2f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0541404156104082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE값 구하기\n",
    "mean_absolute_error(y_valid, automl_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af9d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset의 예측값 구하기\n",
    "pred_test = automl.predict(test[test.columns.difference(['stn'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea3463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 가져오기\n",
    "test_result = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b192b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 넣기\n",
    "test_result['pred_ts'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ccfd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write.csv\n",
    "test_result.to_csv('../data/summer_test_result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e904d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model_name = '002_plan'\n",
    "with open(model_name+'_summer_automl.pickle','wb') as fw:\n",
    "    pickle.dump(automl, fw)\n",
    "\n",
    "# 모델 불러오기\n",
    "# with open('model_210519.pickle', 'rb') as f: \n",
    "#     model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "please",
   "language": "python",
   "name": "please"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
